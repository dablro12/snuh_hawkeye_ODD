from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
import pandas as pd
import numpy as np
from tqdm import tqdm
from IPython import display
# Optional: XGBoost, LightGBM, CatBoost (ì„¤ì¹˜ë˜ì–´ ìˆìœ¼ë©´ ì‚¬ìš©)
try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False

try:
    import lightgbm as lgb
    LIGHTGBM_AVAILABLE = True
except ImportError:
    LIGHTGBM_AVAILABLE = False

try:
    from catboost import CatBoostClassifier
    CATBOOST_AVAILABLE = True
except ImportError:
    CATBOOST_AVAILABLE = False

class ClassifierTrainer:
    """
    Binary Classification Trainer for ODD_CP prediction
    X: ì…ë ¥ feature (DataFrame ë˜ëŠ” array) - ì—°ì†í˜•ê³¼ ë²”ì£¼í˜• ë³€ìˆ˜ ëª¨ë‘ í¬í•¨ ê°€ëŠ¥
    y: Binary target (0 ë˜ëŠ” 1)
    """
    def __init__(self, X, y, X_test=None, y_test=None, random_state=42, n_estimators=500, epoch=100, lr=0.05, n_jobs=-1):
        """
        Parameters:
        -----------
        X : DataFrame or array
            í•™ìŠµìš© feature (ë˜ëŠ” ì „ì²´ ë°ì´í„°)
        y : Series or array
            í•™ìŠµìš© íƒ€ê²Ÿ ë³€ìˆ˜ (ë˜ëŠ” ì „ì²´ ë°ì´í„°)
        X_test : DataFrame or array, optional
            í…ŒìŠ¤íŠ¸ìš© feature (ì œê³µë˜ë©´ XëŠ” train setìœ¼ë¡œ ê°„ì£¼)
        y_test : Series or array, optional
            í…ŒìŠ¤íŠ¸ìš© íƒ€ê²Ÿ ë³€ìˆ˜ (ì œê³µë˜ë©´ yëŠ” train setìœ¼ë¡œ ê°„ì£¼)
        """
        self.n_estimators = n_estimators
        self.epoch = epoch
        self.lr = lr
        self.n_jobs = n_jobs
        self.random_state = random_state
        self.device = "cpu"
        
        # Xê°€ DataFrameì¸ì§€ í™•ì¸
        if isinstance(X, pd.DataFrame):
            self.X_df = X.copy()
            self.feature_names = X.columns.tolist()
        else:
            # numpy arrayì¸ ê²½ìš° DataFrameìœ¼ë¡œ ë³€í™˜
            self.X_df = pd.DataFrame(X)
            self.feature_names = [f'feature_{i}' for i in range(X.shape[1])]
            self.X_df.columns = self.feature_names
        
        # yë¥¼ numpy arrayë¡œ ë³€í™˜ (binary: 0 ë˜ëŠ” 1)
        self.y = np.asarray(y).astype(int)
        
        # Binary classification í™•ì¸
        unique_classes = np.unique(self.y)
        if len(unique_classes) != 2 or not all(c in [0, 1] for c in unique_classes):
            raise ValueError(f"yëŠ” binary classificationì´ì–´ì•¼ í•©ë‹ˆë‹¤ (0 ë˜ëŠ” 1). í˜„ì¬ í´ë˜ìŠ¤: {unique_classes}")
        
        # Test setì´ ì œê³µëœ ê²½ìš° (ì´ë¯¸ ë¶„ë¦¬ëœ ê²½ìš°)
        if X_test is not None and y_test is not None:
            if isinstance(X_test, pd.DataFrame):
                self.X_test = X_test.copy()
            else:
                self.X_test = pd.DataFrame(X_test, columns=self.feature_names)
            self.y_test = np.asarray(y_test).astype(int)
            self.X_train = self.X_df
            self.y_train = self.y
            
            print(f"Train íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„í¬: {np.bincount(self.y_train)} (í´ë˜ìŠ¤ 0: {np.sum(self.y_train==0)}, í´ë˜ìŠ¤ 1: {np.sum(self.y_train==1)})")
            print(f"Test íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„í¬: {np.bincount(self.y_test)} (í´ë˜ìŠ¤ 0: {np.sum(self.y_test==0)}, í´ë˜ìŠ¤ 1: {np.sum(self.y_test==1)})")
        else:
            # Test setì´ ì œê³µë˜ì§€ ì•Šì€ ê²½ìš°: ìë™ìœ¼ë¡œ ë¶„ë¦¬
            print(f"íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„í¬: {np.bincount(self.y)} (í´ë˜ìŠ¤ 0: {np.sum(self.y==0)}, í´ë˜ìŠ¤ 1: {np.sum(self.y==1)})")
            
            # ë°ì´í„° ë¶„ë¦¬
            (
                self.X_train, self.X_test,
                self.y_train, self.y_test
            ) = train_test_split(
                self.X_df, self.y, test_size=0.2,
                random_state=self.random_state,
                stratify=self.y
            )
            print(f"ë°ì´í„° ìë™ ë¶„ë¦¬ ì™„ë£Œ (Train/Test: {len(self.X_train)} / {len(self.X_test)})")
        
        # ë°ì´í„° ëˆ„ìˆ˜(Data Leakage) ê°ì§€ (train setì— ëŒ€í•´ì„œë§Œ)
        self._detect_data_leakage()
        
        # ë²”ì£¼í˜•/ì—°ì†í˜• ë³€ìˆ˜ êµ¬ë¶„
        self._identify_column_types()
        
        # ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ êµ¬ì„±
        self._build_preprocessor()
        
        # ì „ì²˜ë¦¬ ì ìš© (trainìœ¼ë¡œ fit, testë¡œ transform)
        self.X_train_processed = self.preprocessor.fit_transform(self.X_train)
        self.X_test_processed = self.preprocessor.transform(self.X_test)
        
        print(f"ì „ì²˜ë¦¬ ì™„ë£Œ âœ…")
        print(f"  - Train/Test: {len(self.X_train)} / {len(self.X_test)}")
        print(f"  - ì›ë³¸ feature ìˆ˜: {len(self.feature_names)}")
        print(f"  - ì „ì²˜ë¦¬ í›„ feature ìˆ˜: {self.X_train_processed.shape[1]}")
        print(f"  - ë²”ì£¼í˜• ë³€ìˆ˜: {len(self.categorical_cols)}ê°œ")
        print(f"  - ì—°ì†í˜• ë³€ìˆ˜: {len(self.numeric_cols)}ê°œ")
        print("-" * 60)
    
    def _detect_data_leakage(self):
        """ë°ì´í„° ëˆ„ìˆ˜(Data Leakage) ë³€ìˆ˜ ê°ì§€ (train setì— ëŒ€í•´ì„œë§Œ)"""
        leakage_vars = []
        numeric_cols = self.X_train.select_dtypes(include=[np.number]).columns.tolist()
        
        for col in numeric_cols:
            # íƒ€ê²Ÿ ë³€ìˆ˜ì™€ì˜ ì¼ì¹˜ìœ¨ ê³„ì‚° (train set ê¸°ì¤€)
            match_rate = (self.X_train[col] == self.y_train).mean()
            # ìƒê´€ê´€ê³„ ê³„ì‚°
            corr = abs(self.X_train[col].corr(pd.Series(self.y_train)))
            
            # ì¼ì¹˜ìœ¨ì´ 95% ì´ìƒì´ê±°ë‚˜ ìƒê´€ê´€ê³„ê°€ 0.9 ì´ìƒì´ë©´ ê²½ê³ 
            if match_rate >= 0.95 or corr >= 0.9:
                leakage_vars.append({
                    'variable': col,
                    'match_rate': match_rate,
                    'correlation': corr
                })
        
        if leakage_vars:
            print("\nâš ï¸  ë°ì´í„° ëˆ„ìˆ˜(Data Leakage) ê²½ê³ :")
            print("ë‹¤ìŒ ë³€ìˆ˜ë“¤ì´ íƒ€ê²Ÿ ë³€ìˆ˜ì™€ ë§¤ìš° ë†’ì€ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤:")
            for var in leakage_vars:
                print(f"  - {var['variable']}: ì¼ì¹˜ìœ¨ {var['match_rate']:.2%}, ìƒê´€ê´€ê³„ {var['correlation']:.4f}")
            print("ì´ ë³€ìˆ˜ë“¤ì„ ì œê±°í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.\n")
    
    def _identify_column_types(self):
        """ë²”ì£¼í˜•ê³¼ ì—°ì†í˜• ë³€ìˆ˜ ìë™ êµ¬ë¶„ (train set ê¸°ì¤€)"""
        self.categorical_cols = self.X_train.select_dtypes(include=['object']).columns.tolist()
        self.numeric_cols = self.X_train.select_dtypes(include=[np.number]).columns.tolist()
        
        # ë²”ì£¼í˜• ë³€ìˆ˜ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì„¤ì •
        if not self.categorical_cols:
            self.categorical_cols = []
    
    def _build_preprocessor(self):
        """ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ êµ¬ì„±"""
        transformers = []
        
        # ì—°ì†í˜• ë³€ìˆ˜: StandardScaler
        if self.numeric_cols:
            transformers.append(('num', StandardScaler(), self.numeric_cols))
        
        # ë²”ì£¼í˜• ë³€ìˆ˜: OneHotEncoder
        if self.categorical_cols:
            transformers.append(('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), 
                                self.categorical_cols))
        
        if transformers:
            self.preprocessor = ColumnTransformer(
                transformers=transformers,
                remainder='passthrough'
            )
        else:
            # ë³€ìˆ˜ê°€ ì—†ëŠ” ê²½ìš° (ì´ìƒí•œ ê²½ìš°)
            self.preprocessor = StandardScaler()
        
    def print_cls_results(self, y_test, y_pred, model_name):
        """Binary classification ê²°ê³¼ ì¶œë ¥"""
        precision = precision_score(y_test, y_pred, average='binary', zero_division=0)
        recall = recall_score(y_test, y_pred, average='binary', zero_division=0)
        f1 = f1_score(y_test, y_pred, average='binary', zero_division=0)
        acc = accuracy_score(y_test, y_pred)
        
        # Confusion Matrix
        cm = confusion_matrix(y_test, y_pred)
        
        df = pd.DataFrame({
            "Y_True": y_test,
            "Y_Pred": y_pred
        })
        
        print(f"\nğŸ§© Binary Classification ({model_name})")
        print(df.head(10).to_string(index=False))
        print(f"\nğŸ“Š Metrics:")
        print(f"  Accuracy:  {acc:.4f}")
        print(f"  Precision: {precision:.4f}")
        print(f"  Recall:    {recall:.4f}")
        print(f"  F1-Score:  {f1:.4f}")
        print(f"\nğŸ“‹ Confusion Matrix:")
        print(f"              Predicted")
        print(f"              0     1")
        print(f"  Actual 0  {cm[0,0]:4d}  {cm[0,1]:4d}")
        print(f"         1  {cm[1,0]:4d}  {cm[1,1]:4d}")
        print("=" * 60)

    def get_models(self):
        """Binary classification ëª¨ë¸ë“¤ ë°˜í™˜"""
        models = {
            # ê¸°ë³¸ ëª¨ë¸ë“¤
            "LogisticRegression": LogisticRegression(
                max_iter=self.epoch, 
                random_state=self.random_state,
                class_weight='balanced'
            ),
            "SVC": SVC(
                kernel="rbf", 
                C=1.0, 
                probability=True, 
                random_state=self.random_state,
                class_weight='balanced'
            ),
            "RandomForest": RandomForestClassifier(
                n_estimators=self.n_estimators, 
                random_state=self.random_state, 
                n_jobs=self.n_jobs,
                class_weight='balanced'
            ),
            "GradientBoosting": GradientBoostingClassifier(
                random_state=self.random_state,
                n_estimators=self.n_estimators,
                learning_rate=self.lr
            ),
            "MLP": MLPClassifier(
                hidden_layer_sizes=(256, 128), 
                max_iter=self.epoch, 
                random_state=self.random_state
            ),
            
            # ì¶”ê°€ ëª¨ë¸ë“¤
            "AdaBoost": AdaBoostClassifier(
                n_estimators=self.n_estimators,
                learning_rate=self.lr,
                random_state=self.random_state
            ),
            "ExtraTrees": ExtraTreesClassifier(
                n_estimators=self.n_estimators,
                random_state=self.random_state,
                n_jobs=self.n_jobs,
                class_weight='balanced'
            ),
            "DecisionTree": DecisionTreeClassifier(
                random_state=self.random_state,
                class_weight='balanced'
            ),
            "KNN": KNeighborsClassifier(
                n_neighbors=5,
                weights='distance'
            ),
            "NaiveBayes": GaussianNB()
        }
        
        # XGBoost (ì„¤ì¹˜ë˜ì–´ ìˆìœ¼ë©´ ì¶”ê°€)
        if XGBOOST_AVAILABLE:
            models["XGBoost"] = xgb.XGBClassifier(
                n_estimators=self.n_estimators,
                learning_rate=self.lr,
                random_state=self.random_state,
                n_jobs=self.n_jobs,
                eval_metric='logloss',
                use_label_encoder=False
            )
        
        # LightGBM (ì„¤ì¹˜ë˜ì–´ ìˆìœ¼ë©´ ì¶”ê°€)
        if LIGHTGBM_AVAILABLE:
            models["LightGBM"] = lgb.LGBMClassifier(
                n_estimators=self.n_estimators,
                learning_rate=self.lr,
                random_state=self.random_state,
                n_jobs=self.n_jobs,
                class_weight='balanced',
                verbose=-1
            )
        
        # CatBoost (ì„¤ì¹˜ë˜ì–´ ìˆìœ¼ë©´ ì¶”ê°€)
        if CATBOOST_AVAILABLE:
            models["CatBoost"] = CatBoostClassifier(
                iterations=self.n_estimators,
                learning_rate=self.lr,
                random_state=self.random_state,
                verbose=False,
                thread_count=self.n_jobs
            )
        
        return models
    
    def list_available_models(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì¶œë ¥"""
        models = self.get_models()
        print("=" * 60)
        print("ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡")
        print("=" * 60)
        print(f"ì´ {len(models)}ê°œ ëª¨ë¸:")
        for i, name in enumerate(models.keys(), 1):
            print(f"  {i:2d}. {name}")
        
        # Optional ëª¨ë¸ ìƒíƒœ
        print("\nğŸ“¦ Optional ëª¨ë¸ ìƒíƒœ:")
        print(f"  - XGBoost: {'âœ… ì‚¬ìš© ê°€ëŠ¥' if XGBOOST_AVAILABLE else 'âŒ ì„¤ì¹˜ í•„ìš” (pip install xgboost)'}")
        print(f"  - LightGBM: {'âœ… ì‚¬ìš© ê°€ëŠ¥' if LIGHTGBM_AVAILABLE else 'âŒ ì„¤ì¹˜ í•„ìš” (pip install lightgbm)'}")
        print(f"  - CatBoost: {'âœ… ì‚¬ìš© ê°€ëŠ¥' if CATBOOST_AVAILABLE else 'âŒ ì„¤ì¹˜ í•„ìš” (pip install catboost)'}")
        print("=" * 60)
        return list(models.keys())

    def run_all(self, printf=True):
        """ëª¨ë“  ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ - xë¥¼ ë„£ìœ¼ë©´ training í›„ ê²°ê³¼ ë°˜í™˜"""
        models = self.get_models()
        results = []
        self.trained_models = {}  # í•™ìŠµëœ ëª¨ë¸ ì €ì¥

        for name, clf in tqdm(models.items(), desc="Classifierë³„ ì§„í–‰", ncols=80,
                              bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]'):
            if printf:
                print(f"\nğŸš€ {name} ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
                print("-" * 60)

            # ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¡œ í•™ìŠµ
            clf.fit(self.X_train_processed, self.y_train)
            y_pred = np.array(clf.predict(self.X_test_processed)).ravel()

            # í•™ìŠµëœ ëª¨ë¸ ì €ì¥
            self.trained_models[name] = clf

            # Binary classification metrics
            acc = accuracy_score(self.y_test, y_pred)
            precision = precision_score(self.y_test, y_pred, average='binary', zero_division=0)
            recall = recall_score(self.y_test, y_pred, average='binary', zero_division=0)
            f1 = f1_score(self.y_test, y_pred, average='binary', zero_division=0)

            cls_df = pd.DataFrame({
                "y_true": self.y_test,
                "y_pred": y_pred
            })

            if printf:
                self.print_cls_results(self.y_test, y_pred, name)

            results.append({
                "Model": name,
                "Accuracy": round(acc, 4),
                "Precision": round(precision, 4),
                "Recall": round(recall, 4),
                "F1": round(f1, 4),
                "cls_df": cls_df,
                "model": clf  # ëª¨ë¸ ê°ì²´ë„ ì €ì¥
            })

        df_result = pd.DataFrame(results).sort_values("F1", ascending=False)
        if printf:
            print("\nğŸ“Š ì „ì²´ ë¶„ë¥˜ ëª¨ë¸ ë¹„êµ ê²°ê³¼ ìš”ì•½")
            print(df_result[["Model", "Accuracy", "Precision", "Recall", "F1"]].to_string(index=False))
        return df_result
    
    def get_model(self, model_name):
        """í•™ìŠµëœ ëª¨ë¸ ê°€ì ¸ì˜¤ê¸° (run_all() ì‹¤í–‰ í›„ ì‚¬ìš© ê°€ëŠ¥)"""
        if not hasattr(self, 'trained_models') or not self.trained_models:
            raise ValueError("ë¨¼ì € run_all()ì„ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµì‹œì¼œì£¼ì„¸ìš”.")
        
        if model_name not in self.trained_models:
            raise ValueError(f"ëª¨ë¸ '{model_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {list(self.trained_models.keys())}")
        
        return self.trained_models[model_name]
    
    def predict_proba(self, X_new, model_name=None):
        """ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ í™•ë¥  (run_all() ì‹¤í–‰ í›„ ì‚¬ìš© ê°€ëŠ¥)"""
        if not hasattr(self, 'trained_models') or not self.trained_models:
            raise ValueError("ë¨¼ì € run_all()ì„ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµì‹œì¼œì£¼ì„¸ìš”.")
        
        if model_name is None:
            raise ValueError("model_nameì„ ì§€ì •í•´ì£¼ì„¸ìš”. ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: " + ", ".join(self.trained_models.keys()))
        
        if model_name not in self.trained_models:
            raise ValueError(f"ëª¨ë¸ '{model_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {list(self.trained_models.keys())}")
        
        # X_newê°€ DataFrameì´ ì•„ë‹ˆë©´ ë³€í™˜
        if not isinstance(X_new, pd.DataFrame):
            X_new = pd.DataFrame(X_new, columns=self.feature_names)
        
        # ì „ì²˜ë¦¬ ì ìš©
        X_new_processed = self.preprocessor.transform(X_new)
        
        # í•™ìŠµëœ ëª¨ë¸ë¡œ ì˜ˆì¸¡ í™•ë¥  ê³„ì‚°
        model = self.trained_models[model_name]
        y_pred_proba = model.predict_proba(X_new_processed)[:, 1]  # í´ë˜ìŠ¤ 1ì˜ í™•ë¥ 
        
        return y_pred_proba
    
    def predict(self, X_new, model_name=None):
        """ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ (run_all() ì‹¤í–‰ í›„ ì‚¬ìš© ê°€ëŠ¥)"""
        if not hasattr(self, 'trained_models') or not self.trained_models:
            raise ValueError("ë¨¼ì € run_all()ì„ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµì‹œì¼œì£¼ì„¸ìš”.")
        
        if model_name is None:
            raise ValueError("model_nameì„ ì§€ì •í•´ì£¼ì„¸ìš”. ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: " + ", ".join(self.trained_models.keys()))
        
        if model_name not in self.trained_models:
            raise ValueError(f"ëª¨ë¸ '{model_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {list(self.trained_models.keys())}")
        
        # X_newê°€ DataFrameì´ ì•„ë‹ˆë©´ ë³€í™˜
        if not isinstance(X_new, pd.DataFrame):
            X_new = pd.DataFrame(X_new, columns=self.feature_names)
        
        # ì „ì²˜ë¦¬ ì ìš©
        X_new_processed = self.preprocessor.transform(X_new)
        
        # í•™ìŠµëœ ëª¨ë¸ë¡œ ì˜ˆì¸¡
        model = self.trained_models[model_name]
        y_pred = model.predict(X_new_processed)
        y_pred_proba = model.predict_proba(X_new_processed)[:, 1]  # í´ë˜ìŠ¤ 1ì˜ í™•ë¥ 
        
        return y_pred, y_pred_proba


class SoftVotingClassifierTrainer(ClassifierTrainer):
    """
    Soft Voting Classifier Trainer
    ì—¬ëŸ¬ ëª¨ë¸ì˜ ì˜ˆì¸¡ í™•ë¥ ì„ í‰ê· ë‚´ì–´ ìµœì¢… ì˜ˆì¸¡ì„ ìˆ˜í–‰
    """
    def __init__(self, X, y, X_test=None, y_test=None, random_state=42, n_estimators=500, epoch=100, lr=0.05, n_jobs=-1):
        """ClassifierTrainerì™€ ë™ì¼í•œ ì´ˆê¸°í™”"""
        super().__init__(X, y, X_test, y_test, random_state, n_estimators, epoch, lr, n_jobs)
        self.voting_models = {}  # Votingì— ì‚¬ìš©í•  ëª¨ë¸ë“¤ ì €ì¥
    
    def run_all(self, printf=True):
        """ëª¨ë“  ëª¨ë¸ í•™ìŠµ í›„ Soft Votingìœ¼ë¡œ ìµœì¢… ì˜ˆì¸¡"""
        models = self.get_models()
        self.trained_models = {}  # í•™ìŠµëœ ëª¨ë¸ ì €ì¥
        self.voting_models = {}  # Votingì— ì‚¬ìš©í•  ëª¨ë¸ë“¤ (predict_proba ì§€ì›í•˜ëŠ” ëª¨ë¸ë§Œ)
        
        # 1ë‹¨ê³„: ëª¨ë“  ëª¨ë¸ í•™ìŠµ
        if printf:
            print("=" * 60)
            print("1ë‹¨ê³„: ê°œë³„ ëª¨ë¸ í•™ìŠµ")
            print("=" * 60)
        
        for name, clf in tqdm(models.items(), desc="ê°œë³„ ëª¨ë¸ í•™ìŠµ", ncols=80,
                              bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]'):
            try:
                # ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¡œ í•™ìŠµ
                clf.fit(self.X_train_processed, self.y_train)
                
                # í•™ìŠµëœ ëª¨ë¸ ì €ì¥
                self.trained_models[name] = clf
                
                # predict_probaë¥¼ ì§€ì›í•˜ëŠ” ëª¨ë¸ë§Œ votingì— í¬í•¨
                if hasattr(clf, 'predict_proba'):
                    self.voting_models[name] = clf
                    
            except Exception as e:
                if printf:
                    print(f"âš ï¸  {name} ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {e}")
                continue
        
        if printf:
            print(f"\nâœ… ì´ {len(self.trained_models)}ê°œ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
            print(f"âœ… Soft Votingì— {len(self.voting_models)}ê°œ ëª¨ë¸ ì‚¬ìš©")
            print("=" * 60)
        
        # 2ë‹¨ê³„: Soft Votingìœ¼ë¡œ ì˜ˆì¸¡
        if printf:
            print("\n2ë‹¨ê³„: Soft Voting ì˜ˆì¸¡")
            print("=" * 60)
        
        # ëª¨ë“  ëª¨ë¸ì˜ ì˜ˆì¸¡ í™•ë¥  í‰ê·  ê³„ì‚°
        y_proba_sum = np.zeros(len(self.y_test))
        
        for name, clf in self.voting_models.items():
            try:
                y_proba = clf.predict_proba(self.X_test_processed)[:, 1]  # í´ë˜ìŠ¤ 1ì˜ í™•ë¥ 
                y_proba_sum += y_proba
            except Exception as e:
                if printf:
                    print(f"âš ï¸  {name} ì˜ˆì¸¡ í™•ë¥  ê³„ì‚° ì‹¤íŒ¨: {e}")
                continue
        
        # í‰ê·  í™•ë¥  ê³„ì‚°
        y_proba_avg = y_proba_sum / len(self.voting_models)
        
        # ì„ê³„ê°’ 0.5ë¡œ ìµœì¢… ì˜ˆì¸¡
        y_pred = (y_proba_avg >= 0.5).astype(int)
        
        # 3ë‹¨ê³„: í‰ê°€
        acc = accuracy_score(self.y_test, y_pred)
        precision = precision_score(self.y_test, y_pred, average='binary', zero_division=0)
        recall = recall_score(self.y_test, y_pred, average='binary', zero_division=0)
        f1 = f1_score(self.y_test, y_pred, average='binary', zero_division=0)
        
        cls_df = pd.DataFrame({
            "y_true": self.y_test,
            "y_pred": y_pred
        })
        
        if printf:
            print(f"\nğŸ“Š Soft Voting ê²°ê³¼:")
            print(f"  Accuracy:  {acc:.4f}")
            print(f"  Precision: {precision:.4f}")
            print(f"  Recall:    {recall:.4f}")
            print(f"  F1-Score:  {f1:.4f}")
            print(f"\nğŸ“‹ Confusion Matrix:")
            cm = confusion_matrix(self.y_test, y_pred)
            print(f"              Predicted")
            print(f"              0     1")
            print(f"  Actual 0  {cm[0,0]:4d}  {cm[0,1]:4d}")
            print(f"         1  {cm[1,0]:4d}  {cm[1,1]:4d}")
            print("=" * 60)
        
        # ê²°ê³¼ë¥¼ DataFrame í˜•íƒœë¡œ ë°˜í™˜ (ê¸°ì¡´ í˜•ì‹ê³¼ í˜¸í™˜)
        results = [{
            "Model": "SoftVoting",
            "Accuracy": round(acc, 4),
            "Precision": round(precision, 4),
            "Recall": round(recall, 4),
            "F1": round(f1, 4),
            "cls_df": cls_df,
            "model": None  # Votingì€ ë‹¨ì¼ ëª¨ë¸ ê°ì²´ê°€ ì•„ë‹˜
        }]
        
        # ê°œë³„ ëª¨ë¸ ê²°ê³¼ë„ í¬í•¨ (ì„ íƒì‚¬í•­)
        if printf:
            print("\nğŸ“Š ê°œë³„ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ:")
            individual_results = []
            for name, clf in self.trained_models.items():
                try:
                    y_pred_ind = clf.predict(self.X_test_processed)
                    acc_ind = accuracy_score(self.y_test, y_pred_ind)
                    precision_ind = precision_score(self.y_test, y_pred_ind, average='binary', zero_division=0)
                    recall_ind = recall_score(self.y_test, y_pred_ind, average='binary', zero_division=0)
                    f1_ind = f1_score(self.y_test, y_pred_ind, average='binary', zero_division=0)
                    
                    individual_results.append({
                        "Model": name,
                        "Accuracy": round(acc_ind, 4),
                        "Precision": round(precision_ind, 4),
                        "Recall": round(recall_ind, 4),
                        "F1": round(f1_ind, 4)
                    })
                except:
                    continue
            
            if individual_results:
                df_ind = pd.DataFrame(individual_results).sort_values("F1", ascending=False)
                print(df_ind[["Model", "Accuracy", "Precision", "Recall", "F1"]].to_string(index=False))
        
        df_result = pd.DataFrame(results)
        return df_result
    
    def predict_proba(self, X_new, model_name=None):
        """Soft Votingìœ¼ë¡œ ì˜ˆì¸¡ í™•ë¥  ê³„ì‚°"""
        if not hasattr(self, 'voting_models') or not self.voting_models:
            raise ValueError("ë¨¼ì € run_all()ì„ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµì‹œì¼œì£¼ì„¸ìš”.")
        
        # model_name íŒŒë¼ë¯¸í„°ëŠ” ë¬´ì‹œ (Soft Votingì€ ëª¨ë“  ëª¨ë¸ ì‚¬ìš©)
        if not isinstance(X_new, pd.DataFrame):
            X_new = pd.DataFrame(X_new, columns=self.feature_names)
        
        # ì „ì²˜ë¦¬ ì ìš©
        X_new_processed = self.preprocessor.transform(X_new)
        
        # ëª¨ë“  ëª¨ë¸ì˜ ì˜ˆì¸¡ í™•ë¥  í‰ê·  ê³„ì‚°
        y_proba_sum = np.zeros(len(X_new))
        
        for name, clf in self.voting_models.items():
            try:
                y_proba = clf.predict_proba(X_new_processed)[:, 1]
                y_proba_sum += y_proba
            except Exception as e:
                continue
        
        # í‰ê·  í™•ë¥  ë°˜í™˜
        y_proba_avg = y_proba_sum / len(self.voting_models)
        return y_proba_avg
    
    def predict(self, X_new, model_name=None, threshold=0.5):
        """Soft Votingìœ¼ë¡œ ì˜ˆì¸¡"""
        y_proba = self.predict_proba(X_new, model_name)
        y_pred = (y_proba >= threshold).astype(int)
        return y_pred, y_proba



from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from scipy.stats import mode
import numpy as np
import shap
import pandas as pd

# ëª¨ë¸ import
from catboost import CatBoostClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier

try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False
    print("Warning: XGBoost not available")

try:
    import lightgbm as lgb
    LIGHTGBM_AVAILABLE = True
except ImportError:
    LIGHTGBM_AVAILABLE = False
    print("Warning: LightGBM not available")

class MultiModelFoldTrainer:
    """ì—¬ëŸ¬ ëª¨ë¸ì„ ë¹„êµí•˜ëŠ” K-Fold Cross Validation Trainer"""
    
    def __init__(self, models_to_train=None, n_splits=5, random_state=123, T=0.01, sampling_config=None):
        """
        Parameters:
        -----------
        models_to_train : list, optional
            í•™ìŠµí•  ëª¨ë¸ ì´ë¦„ ë¦¬ìŠ¤íŠ¸. Noneì´ë©´ ëª¨ë“  ê°€ëŠ¥í•œ ëª¨ë¸ ì‚¬ìš©
            ê°€ëŠ¥í•œ ëª¨ë¸: 'CatBoost', 'XGBoost', 'LightGBM', 'RandomForest', 
                        'GradientBoosting', 'LogisticRegression', 'SVM', 'MLP'
        n_splits : int
            K-Fold ë¶„í•  ìˆ˜
        random_state : int
            ëœë¤ ì‹œë“œ
        T : float
            Softmax temperature parameter
        sampling_config : dict, optional
            ìƒ˜í”Œë§ ì„¤ì •. Noneì´ë©´ ìƒ˜í”Œë§ ì ìš© ì•ˆ í•¨
            ì˜ˆ: {'type': 'oversample', 'params': {'train_size_per_class': 240, 'method': 'SMOTE'}}
        """
        self.n_splits = n_splits
        self.random_state = random_state
        self.T = T
        self.sampling_config = sampling_config
        
        # ê¸°ë³¸ ëª¨ë¸ ì„¤ì •
        self.model_configs = self._get_model_configs()
        
        # í•™ìŠµí•  ëª¨ë¸ ì„ íƒ
        if models_to_train is None:
            self.models_to_train = list(self.model_configs.keys())
        else:
            self.models_to_train = [m for m in models_to_train if m in self.model_configs]
            if not self.models_to_train:
                raise ValueError(f"ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ê°€ëŠ¥í•œ ëª¨ë¸: {list(self.model_configs.keys())}")
        
        # ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”
        self.metrics = {model: [] for model in self.models_to_train}
        self.test_metrics = {model: [] for model in self.models_to_train}
        self.feature_importances = {model: [] for model in self.models_to_train}
        self.test_proba = {model: [] for model in self.models_to_train}
        self.test_preds = {model: [] for model in self.models_to_train}
        self.fold_thresholds = {model: [] for model in self.models_to_train}
        self.shap_values_train = {model: [] for model in self.models_to_train}
        self.shap_values_test = {model: [] for model in self.models_to_train}
        
        self.fold_weights = {}
        self.weighted_avg_metrics = {}
        self.weighted_avg_test_metrics = {}
        self.y_test = None
    
    def _get_model_configs(self):
        """ëª¨ë¸ ì„¤ì • ë°˜í™˜"""
        configs = {}
        
        # CatBoost ì„¤ì •
        configs['CatBoost'] = {
            'class': CatBoostClassifier,
            'params': dict(
                iterations=1000, learning_rate=0.38577, depth=8, 
                l2_leaf_reg=9.587765, subsample=0.748324, random_strength=0.0, 
                class_weights=[1, 10], min_data_in_leaf=59, 
                leaf_estimation_iterations=1, loss_function='Logloss', 
                eval_metric='AUC', verbose=False, random_seed=self.random_state
            ),
            'has_shap': True
        }
        
        # XGBoost ì„¤ì •
        if XGBOOST_AVAILABLE:
            configs['XGBoost'] = {
                'class': xgb.XGBClassifier,
                'params': dict(
                    n_estimators=1000, learning_rate=0.1, max_depth=8,
                    subsample=0.8, colsample_bytree=0.8, 
                    scale_pos_weight=10, random_state=self.random_state,
                    eval_metric='auc', use_label_encoder=False
                ),
                'has_shap': True
            }
        
        # LightGBM ì„¤ì •
        if LIGHTGBM_AVAILABLE:
            configs['LightGBM'] = {
                'class': lgb.LGBMClassifier,
                'params': dict(
                    n_estimators=1000, learning_rate=0.1, max_depth=8,
                    subsample=0.8, colsample_bytree=0.8,
                    class_weight={0: 1, 1: 10}, random_state=self.random_state,
                    verbose=-1
                ),
                'has_shap': True
            }
        
        # Random Forest ì„¤ì •
        configs['RandomForest'] = {
            'class': RandomForestClassifier,
            'params': dict(
                n_estimators=200, max_depth=15, min_samples_split=5,
                min_samples_leaf=2, class_weight={0: 1, 1: 10},
                random_state=self.random_state, n_jobs=-1
            ),
            'has_shap': True
        }
        
        # Gradient Boosting ì„¤ì •
        configs['GradientBoosting'] = {
            'class': GradientBoostingClassifier,
            'params': dict(
                n_estimators=200, learning_rate=0.1, max_depth=8,
                min_samples_split=5, min_samples_leaf=2,
                random_state=self.random_state
            ),
            'has_shap': True
        }
        
        # Logistic Regression ì„¤ì •
        configs['LogisticRegression'] = {
            'class': LogisticRegression,
            'params': dict(
                C=1.0, class_weight={0: 1, 1: 10},
                random_state=self.random_state, max_iter=1000,
                solver='lbfgs', n_jobs=-1
            ),
            'has_shap': True
        }
        
        # SVM ì„¤ì •
        configs['SVM'] = {
            'class': SVC,
            'params': dict(
                C=1.0, kernel='rbf', probability=True,
                class_weight={0: 1, 1: 10}, random_state=self.random_state
            ),
            'has_shap': False  # SVMì€ SHAP ê³„ì‚°ì´ ëŠë¦¼
        }
        
        # MLP (Neural Network) ì„¤ì •
        configs['MLP'] = {
            'class': MLPClassifier,
            'params': dict(
                hidden_layer_sizes=(100, 50), activation='relu',
                solver='adam', alpha=0.0001, learning_rate='adaptive',
                max_iter=500, random_state=self.random_state, early_stopping=True
            ),
            'has_shap': False  # MLPëŠ” SHAP ê³„ì‚°ì´ ë³µì¡í•¨
        }
        
        return configs
    
    def _create_model(self, model_name):
        """ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
        config = self.model_configs[model_name]
        return config['class'](**config['params'])
    
    def _get_feature_importance(self, model, model_name):
        """ëª¨ë¸ë³„ feature importance ì¶”ì¶œ"""
        if hasattr(model, 'feature_importances_'):
            return model.feature_importances_
        elif hasattr(model, 'get_feature_importance'):
            return model.get_feature_importance()
        else:
            return None
    
    def _get_shap_values(self, model, X, model_name):
        """SHAP values ê³„ì‚°"""
        try:
            config = self.model_configs.get(model_name, {})
            if not config.get('has_shap', False):
                return None
            
            # Tree-based models
            if model_name in ['CatBoost', 'XGBoost', 'LightGBM', 'RandomForest', 'GradientBoosting']:
                explainer = shap.TreeExplainer(model)
                shap_values = explainer.shap_values(X)
                if isinstance(shap_values, list):
                    return shap_values[1]  # binary classification: class 1
                return shap_values
            
            # Linear models (Logistic Regression)
            elif model_name == 'LogisticRegression':
                explainer = shap.LinearExplainer(model, X)
                shap_values = explainer.shap_values(X)
                if isinstance(shap_values, list):
                    return shap_values[1]  # binary classification: class 1
                return shap_values
            
        except Exception as e:
            print(f"Warning: SHAP values ê³„ì‚° ì‹¤íŒ¨ ({model_name}): {e}")
            return None
        return None
    
    def _apply_sampling_to_fold_train(self, X_train_fold, y_train_fold):
        """
        ê° foldì˜ train ë¶€ë¶„ì—ë§Œ ìƒ˜í”Œë§ ì ìš©
        Validation setì€ ì›ë³¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” train ë¶€ë¶„ë§Œ ì²˜ë¦¬
        """
        if self.sampling_config is None:
            return X_train_fold, y_train_fold
        
        sampling_type = self.sampling_config['type']
        params = self.sampling_config['params'].copy()
        params['random_state'] = self.random_state
        
        if sampling_type == 'downsample':
            # Downsampling: í´ë˜ìŠ¤ 0ì„ n_train_class0ê°œë¡œ ì œí•œ
            n_train_class0 = params.get('n_train_class0')
            if n_train_class0 is None:
                # Noneì´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                return X_train_fold, y_train_fold
            
            # í´ë˜ìŠ¤ë³„ ë¶„ë¦¬
            df_train = pd.concat([X_train_fold, y_train_fold], axis=1)
            df_0 = df_train[df_train.iloc[:, -1] == 0]
            df_1 = df_train[df_train.iloc[:, -1] == 1]
            
            # í´ë˜ìŠ¤ 0 ë‹¤ìš´ìƒ˜í”Œë§
            if len(df_0) > n_train_class0:
                df_0 = df_0.sample(n=n_train_class0, random_state=self.random_state)
            
            # í´ë˜ìŠ¤ 1ì€ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            df_train_final = pd.concat([df_0, df_1], axis=0).sample(frac=1, random_state=self.random_state).reset_index(drop=True)
            X_train_resampled = df_train_final.iloc[:, :-1]
            y_train_resampled = df_train_final.iloc[:, -1]
            
            return X_train_resampled, y_train_resampled
        
        elif sampling_type == 'oversample':
            # Oversampling: SMOTE ë“±ì„ ì‚¬ìš©í•˜ì—¬ í´ë˜ìŠ¤ 1ì„ ì˜¤ë²„ìƒ˜í”Œë§
            train_size_per_class = params.get('train_size_per_class', 240)
            method = params.get('method', 'SMOTE')
            
            from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler
            from imblearn.combine import SMOTETomek, SMOTEENN
            
            # í´ë˜ìŠ¤ë³„ ë¶„ë¦¬
            df_train = pd.concat([X_train_fold, y_train_fold], axis=1)
            target_col = df_train.columns[-1]
            df_0 = df_train[df_train[target_col] == 0]
            df_1 = df_train[df_train[target_col] == 1]
            
            # í´ë˜ìŠ¤ 0 ì²˜ë¦¬: train_size_per_classê°œë¡œ ë§ì¶¤ (ë‹¨, ì‹¤ì œ ë°ì´í„° í¬ê¸°ë¥¼ ì´ˆê³¼í•˜ì§€ ì•Šë„ë¡)
            # ê° foldì˜ train ë¶€ë¶„ì€ ì›ë³¸ì˜ ì¼ë¶€ì´ë¯€ë¡œ, train_size_per_classê°€ ì‹¤ì œ í¬ê¸°ë³´ë‹¤ í´ ìˆ˜ ìˆìŒ
            target_size_0 = min(train_size_per_class, len(df_0))
            
            if len(df_0) < target_size_0:
                # ì‹¤ì œë¡œëŠ” ì´ ê²½ìš°ëŠ” ë°œìƒí•˜ì§€ ì•Šì§€ë§Œ ì•ˆì „ì„ ìœ„í•´
                df_0_final = df_0.copy()
            elif len(df_0) > target_size_0:
                df_0_final = df_0.sample(n=target_size_0, random_state=self.random_state)
            else:
                df_0_final = df_0.copy()
            
            # í´ë˜ìŠ¤ 1 ì²˜ë¦¬: SMOTE ë“±ì„ ì‚¬ìš©í•˜ì—¬ train_size_per_classê°œë¡œ ì˜¤ë²„ìƒ˜í”Œë§
            # í´ë˜ìŠ¤ 1ì˜ ê²½ìš°, í´ë˜ìŠ¤ 0ê³¼ ë¹„ìœ¨ì„ ë§ì¶”ê¸° ìœ„í•´ ì˜¤ë²„ìƒ˜í”Œë§
            target_size_1 = train_size_per_class
            
            if len(df_1) < target_size_1:
                # í´ë˜ìŠ¤ 0ê³¼ 1ì„ í•©ì³ì„œ SMOTE ì ìš©
                df_temp = pd.concat([df_0_final, df_1], axis=0)
                X_temp = df_temp.drop(columns=[target_col])
                y_temp = df_temp[target_col]
                
                # k_neighbors ì²´í¬: í´ë˜ìŠ¤ 1ì´ ë„ˆë¬´ ì ìœ¼ë©´ SMOTEê°€ ì‹¤íŒ¨í•  ìˆ˜ ìˆìŒ
                k_neighbors = min(5, max(1, len(df_1) - 1))
                n_neighbors = min(5, max(1, len(df_1) - 1))
                
                method_upper = method.upper()
                try:
                    if 'SMOTEEN' in method_upper:
                        sampler = SMOTEENN(
                            sampling_strategy={0: len(df_0_final), 1: target_size_1},
                            random_state=self.random_state
                        )
                    elif 'SMOTETOMEK' in method_upper:
                        sampler = SMOTETomek(
                            sampling_strategy={0: len(df_0_final), 1: target_size_1},
                            random_state=self.random_state
                        )
                    elif 'ADASYN' in method_upper:
                        sampler = ADASYN(
                            sampling_strategy={0: len(df_0_final), 1: target_size_1},
                            random_state=self.random_state,
                            n_neighbors=n_neighbors
                        )
                    else:  # SMOTE
                        sampler = SMOTE(
                            sampling_strategy={0: len(df_0_final), 1: target_size_1},
                            random_state=self.random_state,
                            k_neighbors=k_neighbors
                        )
                    
                    X_resampled, y_resampled = sampler.fit_resample(X_temp, y_temp)
                    df_resampled = pd.concat([
                        pd.DataFrame(X_resampled, columns=X_train_fold.columns),
                        pd.Series(y_resampled, name=target_col)
                    ], axis=1)
                    
                    # í´ë˜ìŠ¤ë³„ ì¶”ì¶œ
                    df_0_final = df_resampled[df_resampled[target_col] == 0]
                    df_1_final = df_resampled[df_resampled[target_col] == 1]
                    
                except Exception as e:
                    # SMOTE ì‹¤íŒ¨ ì‹œ RandomOverSamplerë¡œ ëŒ€ì²´
                    print(f"    âš ï¸  {method} ìƒ˜í”Œë§ ì‹¤íŒ¨ (í´ë˜ìŠ¤ 1: {len(df_1)}ê°œ), RandomOverSamplerë¡œ ëŒ€ì²´: {e}")
                    ros = RandomOverSampler(
                        sampling_strategy={0: len(df_0_final), 1: target_size_1},
                        random_state=self.random_state
                    )
                    X_resampled, y_resampled = ros.fit_resample(X_temp, y_temp)
                    df_resampled = pd.concat([
                        pd.DataFrame(X_resampled, columns=X_train_fold.columns),
                        pd.Series(y_resampled, name=target_col)
                    ], axis=1)
                    df_0_final = df_resampled[df_resampled[target_col] == 0]
                    df_1_final = df_resampled[df_resampled[target_col] == 1]
                    
            elif len(df_1) > target_size_1:
                df_1_final = df_1.sample(n=target_size_1, random_state=self.random_state)
            else:
                df_1_final = df_1.copy()
            
            # ìµœì¢… train set êµ¬ì„±
            df_train_final = pd.concat([df_0_final, df_1_final], axis=0).sample(frac=1, random_state=self.random_state).reset_index(drop=True)
            X_train_resampled = df_train_final.drop(columns=[target_col])
            y_train_resampled = df_train_final[target_col]
            
            return X_train_resampled, y_train_resampled
        
        # ìƒ˜í”Œë§ì´ ì—†ê±°ë‚˜ ì•Œ ìˆ˜ ì—†ëŠ” íƒ€ì…ì¸ ê²½ìš° ì›ë³¸ ë°˜í™˜
        return X_train_fold, y_train_fold
    
    def fit(self, X, y, X_test, y_test=None):
        """ëª¨ë“  ëª¨ë¸ í•™ìŠµ ë° í‰ê°€"""
        skf = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=self.random_state)
        self.y_test = y_test if y_test is not None else None
        
        # ëª¨ë“  ê²°ê³¼ ì´ˆê¸°í™”
        for model_name in self.models_to_train:
            self.metrics[model_name].clear()
            self.test_metrics[model_name].clear()
            self.feature_importances[model_name].clear()
            self.test_proba[model_name].clear()
            self.test_preds[model_name].clear()
            self.fold_thresholds[model_name].clear()
            self.shap_values_train[model_name].clear()
            self.shap_values_test[model_name].clear()
        
        for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):
            print(f"\n{'='*60}")
            print(f"Fold {fold}/{self.n_splits}")
            print(f"{'='*60}")
            
            # ì›ë³¸ train/val ë¶„í• 
            X_train_orig, X_val = X.iloc[train_idx], X.iloc[val_idx]
            y_train_orig, y_val = y.iloc[train_idx], y.iloc[val_idx]
            
            # ê° foldì˜ train ë¶€ë¶„ì—ë§Œ ìƒ˜í”Œë§ ì ìš© (validationì€ ì›ë³¸ ê·¸ëŒ€ë¡œ)
            X_train, y_train = self._apply_sampling_to_fold_train(X_train_orig, y_train_orig)
            
            print(f"  Train (ì›ë³¸): {len(X_train_orig)}ê°œ â†’ Train (ìƒ˜í”Œë§ í›„): {len(X_train)}ê°œ")
            print(f"  Validation (ì›ë³¸ ê·¸ëŒ€ë¡œ): {len(X_val)}ê°œ")
            print(f"  Train í´ë˜ìŠ¤ ë¶„í¬: {pd.Series(y_train).value_counts().to_dict()}")
            print(f"  Val í´ë˜ìŠ¤ ë¶„í¬: {pd.Series(y_val).value_counts().to_dict()}")
            
            for model_name in self.models_to_train:
                print(f"\n--- {model_name} ---")
                
                # ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
                model = self._create_model(model_name)
                model.fit(X_train, y_train)
                
                # Validation ì˜ˆì¸¡
                val_proba = model.predict_proba(X_val)[:, 1]
                
                # Best threshold ì°¾ê¸° (F1 ê¸°ì¤€)
                thresholds = np.linspace(0, 1, 200)
                f1s = [f1_score(y_val, (val_proba >= t).astype(int), zero_division=0) for t in thresholds]
                best_idx = np.argmax(f1s)
                best_threshold = thresholds[best_idx]
                val_pred_best = (val_proba >= best_threshold).astype(int)
                
                # Validation ë©”íŠ¸ë¦­
                val_metrics = {
                    'Accuracy': accuracy_score(y_val, val_pred_best),
                    'Precision': precision_score(y_val, val_pred_best, zero_division=0),
                    'Recall': recall_score(y_val, val_pred_best, zero_division=0),
                    'F1 Score': f1_score(y_val, val_pred_best, zero_division=0),
                    'ROC AUC Score': roc_auc_score(y_val, val_proba),
                    'Best_Threshold': best_threshold
                }
                self.metrics[model_name].append(val_metrics)
                
                # Feature importance
                feature_imp = self._get_feature_importance(model, model_name)
                if feature_imp is not None:
                    self.feature_importances[model_name].append(feature_imp)
                
                # SHAP values
                shap_train = self._get_shap_values(model, X_train, model_name)
                shap_test = self._get_shap_values(model, X_test, model_name)
                if shap_train is not None:
                    self.shap_values_train[model_name].append(shap_train)
                if shap_test is not None:
                    self.shap_values_test[model_name].append(shap_test)
                
                # Test ì˜ˆì¸¡
                test_proba = model.predict_proba(X_test)[:, 1]
                test_pred = (test_proba >= best_threshold).astype(int)
                self.test_proba[model_name].append(test_proba)
                self.test_preds[model_name].append(test_pred)
                self.fold_thresholds[model_name].append(best_threshold)
                
                # Test ë©”íŠ¸ë¦­
                if y_test is not None:
                    try:
                        test_metrics_fold = {
                            'Accuracy': accuracy_score(y_test, test_pred),
                            'Precision': precision_score(y_test, test_pred, zero_division=0),
                            'Recall': recall_score(y_test, test_pred, zero_division=0),
                            'F1 Score': f1_score(y_test, test_pred, zero_division=0),
                            'ROC AUC Score': roc_auc_score(y_test, test_proba),
                            'Best_Threshold': best_threshold
                        }
                    except Exception as e:
                        test_metrics_fold = {
                            'Accuracy': np.nan, 'Precision': np.nan, 'Recall': np.nan,
                            'F1 Score': np.nan, 'ROC AUC Score': np.nan,
                            'Best_Threshold': best_threshold
                        }
                    self.test_metrics[model_name].append(test_metrics_fold)
                
                print(f"  Val F1: {val_metrics['F1 Score']:.4f}, Val AUC: {val_metrics['ROC AUC Score']:.4f}")
                if y_test is not None:
                    print(f"  Test F1: {test_metrics_fold['F1 Score']:.4f}, Test AUC: {test_metrics_fold['ROC AUC Score']:.4f}")
        
        # ê²°ê³¼ ì¶œë ¥ (ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ì €ì¥ì€ ì§„í–‰ë˜ë„ë¡ try-except ì²˜ë¦¬)
        try:
            self.print_comparison_results()
        except Exception as e:
            print(f"\nâš ï¸  ê²°ê³¼ ì¶œë ¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            print("  (í•™ìŠµì€ ì™„ë£Œë˜ì—ˆìœ¼ë©° ê²°ê³¼ëŠ” ì €ì¥ë©ë‹ˆë‹¤)")
        
        return self
    
    def calc_softmax_weights(self, model_name):
        """ëª¨ë¸ë³„ fold weights ê³„ì‚°"""
        f1_scores = np.array([m['F1 Score'] for m in self.metrics[model_name]])
        exp_scores = np.exp(f1_scores / self.T)
        weights = exp_scores / np.sum(exp_scores)
        self.fold_weights[model_name] = weights
        return weights
    
    def calculate_weighted_metrics(self, model_name):
        """ëª¨ë¸ë³„ weighted í‰ê·  ë©”íŠ¸ë¦­"""
        weights = self.calc_softmax_weights(model_name)
        metric_keys = [k for k in self.metrics[model_name][0] if k != 'Best_Threshold']
        weighted_metrics = {
            metric: sum(w * m[metric] for w, m in zip(weights, self.metrics[model_name]))
            for metric in metric_keys
        }
        self.weighted_avg_metrics[model_name] = weighted_metrics
        return weighted_metrics
    
    def calculate_weighted_test_metrics(self, model_name):
        """ëª¨ë¸ë³„ weighted test ë©”íŠ¸ë¦­"""
        if len(self.test_metrics[model_name]) == 0:
            return None
        weights = self.calc_softmax_weights(model_name)
        metric_keys = [k for k in self.test_metrics[model_name][0] if k != 'Best_Threshold']
        weighted_metrics = {
            metric: sum(w * m[metric] for w, m in zip(weights, self.test_metrics[model_name]))
            for metric in metric_keys
        }
        self.weighted_avg_test_metrics[model_name] = weighted_metrics
        return weighted_metrics
    
    def print_comparison_results(self):
        """ëª¨ë“  ëª¨ë¸ ë¹„êµ ê²°ê³¼ ì¶œë ¥"""
        print("\n" + "="*80)
        print("ëª¨ë¸ ë¹„êµ ê²°ê³¼ (Weighted Average)")
        print("="*80)
        
        # Validation ê²°ê³¼ ë¹„êµ
        print("\n[Validation Set]")
        print("-"*80)
        comparison_data = []
        for model_name in self.models_to_train:
            weighted_metrics = self.calculate_weighted_metrics(model_name)
            comparison_data.append({
                'Model': model_name,
                **weighted_metrics
            })
        
        comparison_df = pd.DataFrame(comparison_data)
        comparison_df = comparison_df.sort_values('F1 Score', ascending=False)
        print(comparison_df.to_string(index=False))
        
        # Test ê²°ê³¼ ë¹„êµ
        if self.y_test is not None:
            print("\n[Test Set]")
            print("-"*80)
            test_comparison_data = []
            for model_name in self.models_to_train:
                weighted_test_metrics = self.calculate_weighted_test_metrics(model_name)
                if weighted_test_metrics:
                    test_comparison_data.append({
                        'Model': model_name,
                        **weighted_test_metrics
                    })
            
            if test_comparison_data:
                test_comparison_df = pd.DataFrame(test_comparison_data)
                test_comparison_df = test_comparison_df.sort_values('F1 Score', ascending=False)
                print(test_comparison_df.to_string(index=False))
        
        # Best ëª¨ë¸ ì¶œë ¥
        best_model = comparison_df.iloc[0]['Model']
        print(f"\nğŸ† Best Model (Validation F1): {best_model}")
        print(f"   F1 Score: {comparison_df.iloc[0]['F1 Score']:.4f}")
        print(f"   ROC AUC: {comparison_df.iloc[0]['ROC AUC Score']:.4f}")
    
    # Getter ë©”ì„œë“œë“¤
    def get_val_metrics(self):
        return self.metrics
    
    def get_test_metrics(self):
        return self.test_metrics
    
    def get_feature_importances(self):
        return self.feature_importances
    
    def get_test_labels(self):
        return self.y_test
    
    def get_test_proba(self):
        return self.test_proba
    
    def get_test_preds(self):
        return self.test_preds
    
    def get_fold_thresholds(self):
        return self.fold_thresholds
    
    def get_shap_values_train(self):
        return self.shap_values_train
    
    def get_shap_values_test(self):
        return self.shap_values_test

# ì‚¬ìš© ì˜ˆì‹œ: ëª¨ë“  ëª¨ë¸ ë¹„êµ
# models_to_train=Noneì´ë©´ ëª¨ë“  ê°€ëŠ¥í•œ ëª¨ë¸ ì‚¬ìš©
# ë˜ëŠ” íŠ¹ì • ëª¨ë¸ë§Œ ì„ íƒ: ['CatBoost', 'RandomForest', 'LogisticRegression'] ë“±
# 
# ì£¼ì˜: ì•„ë˜ ì½”ë“œëŠ” ëª¨ë“ˆ import ì‹œ ì‹¤í–‰ë˜ì§€ ì•Šë„ë¡ ì£¼ì„ ì²˜ë¦¬ë¨
# ë…¸íŠ¸ë¶ì´ë‚˜ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì§ì ‘ ì‚¬ìš©í•  ë•Œë§Œ ì£¼ì„ì„ í•´ì œí•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”
#
# multi_model_trainer = MultiModelFoldTrainer(
#     models_to_train=None,  # Noneì´ë©´ ëª¨ë“  ê°€ëŠ¥í•œ ëª¨ë¸ ì‚¬ìš©
#     # models_to_train=['CatBoost', 'XGBoost', 'LightGBM', 'RandomForest', 'GradientBoosting', 'LogisticRegression'],  # íŠ¹ì • ëª¨ë¸ë§Œ ì„ íƒ
#     n_splits=5, 
#     random_state=42, 
#     T=0.01
# )
# multi_model_trainer.fit(X_train, y_train, X_test, y_test=y_test)